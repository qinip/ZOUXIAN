[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "WHAT IS ZOUXIAN?",
    "section": "",
    "text": "“Zouxian” is a Chinese term meaning “walking the line.” It refers to the perilous journey undertaken by Chinese migrants through the Darién Gap, a dangerous jungle in Panama, as they attempt to reach the United States. This route is chosen by those seeking asylum due to deteriorating economic prospects and political oppression in China. The surge of Chinese migrants crossing the southern U.S. border, particularly through the Darién Gap, represents a significant shift in migration patterns. Driven by concerns over economic uncertainty and political repression in China, these migrants are undertaking a perilous journey, often guided by information shared on social media. They typically seek asylum upon arrival, citing fears of persecution in their homeland. This increase is noteworthy, as historically, Chinese migration to the U.S. has been through more conventional routes, such as education or work visas.\n \nLEARN MORE\n\nNYT\nWSJ\nBBC"
  },
  {
    "objectID": "p1.html",
    "href": "p1.html",
    "title": "The Start",
    "section": "",
    "text": "The COVID-19 outbreak in 2020 has fuelled an increase in the urban youth’s desire to leave China. This is due to severe lockdown measures disrupting daily life and causing panic, hastily introduced government policies like the ‘Three-Child Policy’ and ‘Double Reduction Policy’ adding societal and economic pressures, and increasing burdens on people, notably women and parents. Additionally, shrinking opportunities for educational upward mobility, expanding censorship, worsening Western diplomatic relations, and fears of further international isolation due to the pandemic have made emigration more attractive to younger generations.\nIn this context, the concept of “Rùn” has gained significant traction. “Rùn” is a term currently being utilized interchangeably with the English word ‘run’ to symbolize a strong desire to emigrate out of China. The term has become especially popular among Chinese urban youth, who long for a future where they can live autonomously without being chained to societal pressures and have a reasonable level of control over their lives. Their will to “run” often represents the pursuit of freedom, individual autonomy, better opportunities, and a less stressful lifestyle. Women of reproductive age, in particular, have shown a significant interest in “Rùn” as they face additional societal stressors like age-based and maternity-based discrimination in employment, gender inequality, and the pressure to have up to three children due to China’s new policy.\nAmidst these circumstances, the emergence of “zouxian,” a risky journey involving Chinese people walking through South and Central America to enter the US via its Southern border, can be understood as an extreme, desperate manifestation of the desire to “Rùn.”\n\n\nCode\n## Prepare google trends data for plotting\ntrends &lt;- read_csv(\"data/google_trends.csv\")\ncolnames(trends) &lt;- c(\"Week\", \"Search_Emigrate\", \"Search_Zouxian\")\n\n## Convert Week to Year and Month and\n## Get the sum of search for each month\ntrends &lt;- trends %&gt;% \n  mutate(Date = as.Date(Week, format = \"%m/%d/%y\"),\n         Year = as.numeric(format(Date, \"%Y\")),\n         Month = as.numeric(format(Date, \"%m\")),\n         Search_Emigrate = as.integer(Search_Emigrate),\n         Search_Zouxian = as.integer(Search_Zouxian)) %&gt;% \n  group_by(Year, Month) %&gt;%\n  summarise(Search_Emigrate = sum(Search_Emigrate, na.rm = TRUE),\n            Search_Zouxian = sum(Search_Zouxian, na.rm = TRUE)) %&gt;%\n  ungroup() %&gt;% \n  mutate(Date = paste(Year, Month, sep = \"-\")) %&gt;%  # Combine year and month to Date\n  select(Date, Search_Emigrate, Search_Zouxian) %&gt;% \n  # Remove the last row as it is incomplete\n  filter(Date != \"2023-12\")\n  \n\n## Stardardize the Search_Emigrate using min-max normalization and ajust the scale scale for Search_Zouxian accordingly\nrange = max(trends$Search_Emigrate) - min(trends$Search_Emigrate)\ntrends &lt;- trends %&gt;% \n  mutate(Search_Emigrate = 100 * (Search_Emigrate - min(Search_Emigrate)) / range,\n         Search_Zouxian = Search_Zouxian * (100/range))\n\n\n## Plot the google trends data with a line chart\ntrends$Date &lt;- gsub(\"-(\\\\d)$\", \"-0\\\\1\", trends$Date)\ntrends$Date &lt;- as.yearmon(trends$Date, \"%Y-%m\")\nbreaks &lt;- seq(min(trends$Date), max(trends$Date), by = 4/12)\n\np &lt;- ggplot(trends, aes(x = Date)) +\n  geom_point(aes(y = Search_Emigrate, color = 'Search_Emigrate'), size = 1.5 ) +\n  geom_line(aes(y = Search_Emigrate, color = 'Search_Emigrate'), size = 1) +\n  geom_point(aes(y = Search_Zouxian, color = 'Search_Zouxian'), size = 1.5 ) +\n  geom_line(aes(y = Search_Zouxian, color = 'Search_Zouxian'), size = 1) +\n  geom_rect(aes(xmin = as.yearmon(\"2020-01\"), xmax = as.yearmon(\"2020-04\"), ymin = -Inf, ymax = Inf), fill = \"lightgrey\", alpha = 0.01) +\n  geom_rect(aes(xmin = as.yearmon(\"2022-02\"), xmax = as.yearmon(\"2022-08\"), ymin = -Inf, ymax = Inf), fill = \"lightgrey\", alpha = 0.01) +\n  ggplot2::annotate(\"text\", x = as.yearmon(\"2020-02\")+0.1, y = 93, label = \"Wuhan \\nLockdown\", color = \"black\",size = 3, family=\"Charter\") +\n  ggplot2::annotate(\"text\", x = as.yearmon(\"2022-05\"), y = 93, label = \"Shanghai \\nLockdown\", color = \"black\", size = 3, family=\"Charter\") +\n  scale_x_yearmon(breaks = breaks, labels = date_format(\"%Y-%m\")) +\n  labs(title = \"Monthly Search Popularity for Emigration and \\\"Zouxian\\\" 2020-2023\",\n       subtitle = \"Major city lockdowns to manage the pandemic sparked a surge in online searches.\",\n       x = \"Date\", y = \"Google Search Popularity \\n(Peak of the search for \\\"emigrate\\\"=100)\") +\n ggplot2::annotate(\"text\", x = Inf, y = 0, vjust = 6, hjust = 1.2,\n            colour = \"black\",\n            label = \"Source: Google Trends\", size = 3, family=\"Charter\") +\n  coord_cartesian(clip=\"off\") +\n  theme_hc() +\n  theme(axis.text.x = element_text(angle = 0),\n        text=element_text(size=11,  family=\"Charter\"), \n        legend.position = c(0.85,0.85),\n        legend.title = element_blank(),\n        legend.spacing.x = unit(0, \"cm\"),\n        legend.spacing.y = unit(0, \"cm\") \n        ) +        \n  scale_color_manual(values = c('Search_Emigrate' = 'darkblue', 'Search_Zouxian' = 'darkorange'))\n\np"
  },
  {
    "objectID": "p1.html#a-growing-desire-to-emigrate-out",
    "href": "p1.html#a-growing-desire-to-emigrate-out",
    "title": "The Start",
    "section": "",
    "text": "The COVID-19 outbreak in 2020 has fuelled an increase in the urban youth’s desire to leave China. This is due to severe lockdown measures disrupting daily life and causing panic, hastily introduced government policies like the ‘Three-Child Policy’ and ‘Double Reduction Policy’ adding societal and economic pressures, and increasing burdens on people, notably women and parents. Additionally, shrinking opportunities for educational upward mobility, expanding censorship, worsening Western diplomatic relations, and fears of further international isolation due to the pandemic have made emigration more attractive to younger generations.\nIn this context, the concept of “Rùn” has gained significant traction. “Rùn” is a term currently being utilized interchangeably with the English word ‘run’ to symbolize a strong desire to emigrate out of China. The term has become especially popular among Chinese urban youth, who long for a future where they can live autonomously without being chained to societal pressures and have a reasonable level of control over their lives. Their will to “run” often represents the pursuit of freedom, individual autonomy, better opportunities, and a less stressful lifestyle. Women of reproductive age, in particular, have shown a significant interest in “Rùn” as they face additional societal stressors like age-based and maternity-based discrimination in employment, gender inequality, and the pressure to have up to three children due to China’s new policy.\nAmidst these circumstances, the emergence of “zouxian,” a risky journey involving Chinese people walking through South and Central America to enter the US via its Southern border, can be understood as an extreme, desperate manifestation of the desire to “Rùn.”\n\n\nCode\n## Prepare google trends data for plotting\ntrends &lt;- read_csv(\"data/google_trends.csv\")\ncolnames(trends) &lt;- c(\"Week\", \"Search_Emigrate\", \"Search_Zouxian\")\n\n## Convert Week to Year and Month and\n## Get the sum of search for each month\ntrends &lt;- trends %&gt;% \n  mutate(Date = as.Date(Week, format = \"%m/%d/%y\"),\n         Year = as.numeric(format(Date, \"%Y\")),\n         Month = as.numeric(format(Date, \"%m\")),\n         Search_Emigrate = as.integer(Search_Emigrate),\n         Search_Zouxian = as.integer(Search_Zouxian)) %&gt;% \n  group_by(Year, Month) %&gt;%\n  summarise(Search_Emigrate = sum(Search_Emigrate, na.rm = TRUE),\n            Search_Zouxian = sum(Search_Zouxian, na.rm = TRUE)) %&gt;%\n  ungroup() %&gt;% \n  mutate(Date = paste(Year, Month, sep = \"-\")) %&gt;%  # Combine year and month to Date\n  select(Date, Search_Emigrate, Search_Zouxian) %&gt;% \n  # Remove the last row as it is incomplete\n  filter(Date != \"2023-12\")\n  \n\n## Stardardize the Search_Emigrate using min-max normalization and ajust the scale scale for Search_Zouxian accordingly\nrange = max(trends$Search_Emigrate) - min(trends$Search_Emigrate)\ntrends &lt;- trends %&gt;% \n  mutate(Search_Emigrate = 100 * (Search_Emigrate - min(Search_Emigrate)) / range,\n         Search_Zouxian = Search_Zouxian * (100/range))\n\n\n## Plot the google trends data with a line chart\ntrends$Date &lt;- gsub(\"-(\\\\d)$\", \"-0\\\\1\", trends$Date)\ntrends$Date &lt;- as.yearmon(trends$Date, \"%Y-%m\")\nbreaks &lt;- seq(min(trends$Date), max(trends$Date), by = 4/12)\n\np &lt;- ggplot(trends, aes(x = Date)) +\n  geom_point(aes(y = Search_Emigrate, color = 'Search_Emigrate'), size = 1.5 ) +\n  geom_line(aes(y = Search_Emigrate, color = 'Search_Emigrate'), size = 1) +\n  geom_point(aes(y = Search_Zouxian, color = 'Search_Zouxian'), size = 1.5 ) +\n  geom_line(aes(y = Search_Zouxian, color = 'Search_Zouxian'), size = 1) +\n  geom_rect(aes(xmin = as.yearmon(\"2020-01\"), xmax = as.yearmon(\"2020-04\"), ymin = -Inf, ymax = Inf), fill = \"lightgrey\", alpha = 0.01) +\n  geom_rect(aes(xmin = as.yearmon(\"2022-02\"), xmax = as.yearmon(\"2022-08\"), ymin = -Inf, ymax = Inf), fill = \"lightgrey\", alpha = 0.01) +\n  ggplot2::annotate(\"text\", x = as.yearmon(\"2020-02\")+0.1, y = 93, label = \"Wuhan \\nLockdown\", color = \"black\",size = 3, family=\"Charter\") +\n  ggplot2::annotate(\"text\", x = as.yearmon(\"2022-05\"), y = 93, label = \"Shanghai \\nLockdown\", color = \"black\", size = 3, family=\"Charter\") +\n  scale_x_yearmon(breaks = breaks, labels = date_format(\"%Y-%m\")) +\n  labs(title = \"Monthly Search Popularity for Emigration and \\\"Zouxian\\\" 2020-2023\",\n       subtitle = \"Major city lockdowns to manage the pandemic sparked a surge in online searches.\",\n       x = \"Date\", y = \"Google Search Popularity \\n(Peak of the search for \\\"emigrate\\\"=100)\") +\n ggplot2::annotate(\"text\", x = Inf, y = 0, vjust = 6, hjust = 1.2,\n            colour = \"black\",\n            label = \"Source: Google Trends\", size = 3, family=\"Charter\") +\n  coord_cartesian(clip=\"off\") +\n  theme_hc() +\n  theme(axis.text.x = element_text(angle = 0),\n        text=element_text(size=11,  family=\"Charter\"), \n        legend.position = c(0.85,0.85),\n        legend.title = element_blank(),\n        legend.spacing.x = unit(0, \"cm\"),\n        legend.spacing.y = unit(0, \"cm\") \n        ) +        \n  scale_color_manual(values = c('Search_Emigrate' = 'darkblue', 'Search_Zouxian' = 'darkorange'))\n\np"
  },
  {
    "objectID": "p1.html#reasons-to-rùn",
    "href": "p1.html#reasons-to-rùn",
    "title": "The Start",
    "section": "Reasons to “Rùn”",
    "text": "Reasons to “Rùn”\nThe decision to leave China permanently is driven by a myriad of factors. First, economic opportunities often lure Chinese citizens to emigrate. Many are attracted by a higher standard of living and better job prospects. Second, they aim to provide a better environment for their children, with desirable overseas education and healthier upbringing conditions being highly valued. Moreover, the safer and more regulated social atmosphere, the protection under the rule of law, and more personal and political freedoms in other countries serve as significant pull factors. These rights and legal protection, which might be lacking or inconsistent in China, are crucial attractions for those considering permanent departure.\nFor those resorting to the extreme “zouxian” option, it is often the culmination of a sense of desperation and lack of alternatives. Due to restrictive visa policies, financial constraints, or lack of assets that could facilitate safer immigration options, they see “zouxian” as their only avenue for leaving. Despite the inherent risks, these individuals feel compelled to take the leap, reflecting the extent of their dissatisfaction and desperation within the prevailing circumstances in China.\nVoice of America (VOA) presents a series of valuable insights through interviews conducted with successful emigrants in various countries, including Thailand, Australia, and the U.S. These narratives encompass diverse emigration methods, including illegal border crossing. By examining their experiences and motivations, we can better understand the prevailing reasons driving the Chinese people’s legal or illegal emigration.\n\n\n Interviews (in Chinese): VOA"
  },
  {
    "objectID": "p3.html",
    "href": "p3.html",
    "title": "The Repercussions",
    "section": "",
    "text": "n 2023, the United States witnessed a disconcerting surge in Chinese migrants crossing the border. While the influx began in 2022 and secured some media spotlight in March and April of that year, the staggering rise did not stir widespread concern until later.\nIn September, Senator Roger Marshall, along with several fellow Republicans, spotlighted the issue. They issued an open letter to the Department of Homeland Security (DHS) demanding responses, citing national security fears.\nThe issue of Chinese migrants crossing the U.S. border truly entered public consciousness only in the recent month, specifically in late November and early December. The escalating crisis triggered by the overall surge of border crosser, coupled with the Republicans’ heightened emphasis on border security in Congress and presidential primary campaigns, have prompted influential outlets like The New York Times to publish two special report articles on the issue within a week. As depicted in the provided graphic, the topic has also become a hotspot in Google searches. This sudden surge in public interest and media coverage has placed the spotlight on not only the immediate situation at the border, but also on its potential repercussions on Chinese migrants and Chinese residents in the U.S. alike.\n\nAs tension heightens in the international relations between the US and China, punctuated by high-profile incidents such as the spy balloon saga and repeated military provocations, public sentiment towards this growing phenomenon is shifting. This shift has the potential to impact not only the fate of these asylum seekers but also the Chinese population residing legally in the US."
  },
  {
    "objectID": "p3.html#raising-concerns",
    "href": "p3.html#raising-concerns",
    "title": "The Repercussions",
    "section": "",
    "text": "n 2023, the United States witnessed a disconcerting surge in Chinese migrants crossing the border. While the influx began in 2022 and secured some media spotlight in March and April of that year, the staggering rise did not stir widespread concern until later.\nIn September, Senator Roger Marshall, along with several fellow Republicans, spotlighted the issue. They issued an open letter to the Department of Homeland Security (DHS) demanding responses, citing national security fears.\nThe issue of Chinese migrants crossing the U.S. border truly entered public consciousness only in the recent month, specifically in late November and early December. The escalating crisis triggered by the overall surge of border crosser, coupled with the Republicans’ heightened emphasis on border security in Congress and presidential primary campaigns, have prompted influential outlets like The New York Times to publish two special report articles on the issue within a week. As depicted in the provided graphic, the topic has also become a hotspot in Google searches. This sudden surge in public interest and media coverage has placed the spotlight on not only the immediate situation at the border, but also on its potential repercussions on Chinese migrants and Chinese residents in the U.S. alike.\n\nAs tension heightens in the international relations between the US and China, punctuated by high-profile incidents such as the spy balloon saga and repeated military provocations, public sentiment towards this growing phenomenon is shifting. This shift has the potential to impact not only the fate of these asylum seekers but also the Chinese population residing legally in the US."
  },
  {
    "objectID": "p3.html#how-the-public-perceives-the-influx",
    "href": "p3.html#how-the-public-perceives-the-influx",
    "title": "The Repercussions",
    "section": "How the Public Perceives the Influx",
    "text": "How the Public Perceives the Influx\nTo gauge public opinion on this emerging crisis, I have amassed around 15,000 comments from US internet users. These comments, posted in response to news coverage of this situation, present an opportunity to examine firsthand how this dramatic influx is perceived by the public.\n\n\nThe analysis of the polar chart revealed consistent emotional patterns across all media platforms, with a pronounced presence of ‘anticipation’ and a delicate equilibrium between ‘positive’ and ‘negative’ sentiments, particularly evident in the commentary on YouTube and TikTok. Newspaper comments, however, displayed a higher degree of positivity, indicating a distinct emotional trend within traditional media outlets. Interestingly, ‘surprise’ registered as a subdued emotion across the platforms, suggesting that despite the dynamic nature of social media discourse, users’ reactions tend to be more predictable than one might assume."
  },
  {
    "objectID": "p3.html#whats-next",
    "href": "p3.html#whats-next",
    "title": "The Repercussions",
    "section": "What’s next?",
    "text": "What’s next?\nIn the context of online narratives in China, the notion of ‘successful wiring’—a metaphor for successful emigration and integration abroad—is often met with skepticism. A prevalent view amongst many Chinese netizens is that if one cannot thrive in China, success is equally unattainable in the United States. However, this perspective fails to consider the increasingly significant role Chinese emigrants play in American politics and the forthcoming elections, where they are often portrayed as both a danger and a resourceful entity, encompassing spies and military personnel. For these individuals, ‘successful wiring’ may not represent a final destination but rather the beginning of a longer and more arduous journey, filled with unforeseen challenges and hardships. The path they navigate is complex, leading to a future that unfolds in unexpected ways, far beyond the initial act of emigration."
  },
  {
    "objectID": "scripts/voa_prep.html",
    "href": "scripts/voa_prep.html",
    "title": "voa_prep",
    "section": "",
    "text": "library(readxl)\nlibrary(quanteda)\n\nPackage version: 3.3.1\nUnicode version: 14.0\nICU version: 71.1\n\n\nParallel computing: 8 of 8 threads used.\n\n\nSee https://quanteda.io for tutorials and examples.\n\nlibrary(textTinyR)\n\nLoading required package: Matrix\n\nlibrary(tm)\n\nLoading required package: NLP\n\n\n\nAttaching package: 'NLP'\n\n\nThe following objects are masked from 'package:quanteda':\n\n    meta, meta&lt;-\n\n\n\nAttaching package: 'tm'\n\n\nThe following object is masked from 'package:quanteda':\n\n    stopwords\n\nlibrary(topicmodels)\nlibrary(RColorBrewer)\nlibrary(udpipe)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ ggplot2::annotate() masks NLP::annotate()\n✖ tidyr::expand()     masks Matrix::expand()\n✖ dplyr::filter()     masks stats::filter()\n✖ dplyr::lag()        masks stats::lag()\n✖ tidyr::pack()       masks Matrix::pack()\n✖ tidyr::unpack()     masks Matrix::unpack()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(data.table)\n\n\nAttaching package: 'data.table'\n\nThe following objects are masked from 'package:lubridate':\n\n    hour, isoweek, mday, minute, month, quarter, second, wday, week,\n    yday, year\n\nThe following objects are masked from 'package:dplyr':\n\n    between, first, last\n\nThe following object is masked from 'package:purrr':\n\n    transpose\n\nlibrary(jsonlite)\n\n\nAttaching package: 'jsonlite'\n\nThe following object is masked from 'package:purrr':\n\n    flatten\n\n## Prepare data for plotting\ninterviews &lt;- read_excel(\"../data/interviews.xlsx\")\n## label POS\nud_model &lt;- udpipe_download_model(language = \"english\")\n\nDownloading udpipe model from https://raw.githubusercontent.com/jwijffels/udpipe.models.ud.2.5/master/inst/udpipe-ud-2.5-191206/english-ewt-ud-2.5-191206.udpipe to /Users/zhiqiangji/GitRepos/ZOUXIAN/scripts/english-ewt-ud-2.5-191206.udpipe\n - This model has been trained on version 2.5 of data from https://universaldependencies.org\n - The model is distributed under the CC-BY-SA-NC license: https://creativecommons.org/licenses/by-nc-sa/4.0\n - Visit https://github.com/jwijffels/udpipe.models.ud.2.5 for model license details.\n - For a list of all models and their licenses (most models you can download with this package have either a CC-BY-SA or a CC-BY-SA-NC license) read the documentation at ?udpipe_download_model. For building your own models: visit the documentation by typing vignette('udpipe-train', package = 'udpipe')\nDownloading finished, model stored at '/Users/zhiqiangji/GitRepos/ZOUXIAN/scripts/english-ewt-ud-2.5-191206.udpipe'\n\nud_model &lt;- udpipe_load_model(ud_model$file_model)\ninterviews_annotated &lt;-  udpipe_annotate(ud_model, x = interviews$text)\ndt &lt;- as.data.table(interviews_annotated)\ndt_filtered &lt;- dt[upos %in% c(\"NOUN\", \"VERB\")]\ncorpus &lt;- Corpus(VectorSource(dt_filtered$lemma))\n\n# Preprocessing\ncorpus_clean &lt;- tm_map(corpus, content_transformer(tolower))\n\nWarning in tm_map.SimpleCorpus(corpus, content_transformer(tolower)):\ntransformation drops documents\n\ncorpus_clean &lt;- tm_map(corpus_clean, content_transformer(removePunctuation))\n\nWarning in tm_map.SimpleCorpus(corpus_clean,\ncontent_transformer(removePunctuation)): transformation drops documents\n\ncorpus_clean &lt;- tm_map(corpus_clean, content_transformer(removeNumbers))\n\nWarning in tm_map.SimpleCorpus(corpus_clean,\ncontent_transformer(removeNumbers)): transformation drops documents\n\ncorpus_clean &lt;- tm_map(corpus_clean, content_transformer(removeWords), stopwords(\"english\"))\n\nWarning in tm_map.SimpleCorpus(corpus_clean, content_transformer(removeWords),\n: transformation drops documents\n\n# Create a document-term matrix\ndtm &lt;- DocumentTermMatrix(corpus_clean)\ndtm &lt;- removeSparseTerms(dtm, 0.99) \n\n# Convert your TDM to a non-sparse format (required by LDA)\ndtm_lda &lt;- as.DocumentTermMatrix(dtm, control = list(store = \"dense\"))\n# remove all-zero rows\ndtm_lda &lt;- dtm_lda[rowSums(as.matrix(dtm_lda)) &gt; 0, ]\n\n\n# Determine number of topics\nk &lt;- 5  \n# Apply LDA\nlda_model &lt;- LDA(dtm_lda, k, method = \"Gibbs\", control = list(seed = 42))\n\ntop_terms &lt;- terms(lda_model, 20)\n\n# Store top terms as a data frame for plotting\ntop_terms_df &lt;- data.frame(t(top_terms))\ntop_terms_df$topic &lt;- seq_len(nrow(top_terms_df))\ntop_terms_df$words &lt;- apply(top_terms_df[, -ncol(top_terms_df)], 1, paste, collapse = \" \")\ntop_terms_df &lt;- top_terms_df[, c(\"topic\", \"words\")]\nhead(top_terms_df)\n\n        topic                                                 words\nTopic 1     1 say take come year leave country know people time day\nTopic 2     2 people day year country take know say come leave time\nTopic 3     3 year country leave come take know people say time day\nTopic 4     4 leave know say day year country take people come time\nTopic 5     5 time come country year take know people say leave day\n\n# Save as CSV\nwrite.csv(top_terms_df, \"../data/voa_top_terms.csv\", row.names = FALSE)\n\n\n# Prepare data for page 3\n## read in csv file\n## Read in the data from file\ncomments &lt;- read_csv(\"../data/all_comments_nlp.csv\") %&gt;%\n  select(user, source, polarity_subjectivity, emotion_scores) # select only the columns needed for the app\n\nRows: 13907 Columns: 9\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (6): user, text, source, text_clean, polarity_subjectivity, emotion_scores\ndbl (3): mentions, unique_words, length\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n## Get the column names\ncolnames(comments)\n\n[1] \"user\"                  \"source\"                \"polarity_subjectivity\"\n[4] \"emotion_scores\"       \n\n## Create a df for emotion score plotting\ncomments$emotion_scores &lt;- str_replace_all(comments$emotion_scores, \"'\", \"\\\"\")\n\n# Convert emotion_scores from JSON-like strings to lists\ncomments &lt;- comments %&gt;%\n  mutate(emotion_scores = map(emotion_scores, ~fromJSON(.x, simplifyVector = TRUE)))\n\n# Unnest the nested emotion_scores list-column to two columns, name and value\ncomments &lt;- tidyr::unnest_wider(comments, emotion_scores)\n\n# Gather all emotions into one column and their corresponding values into another column\n# Gather all emotions into one column and their corresponding values into another column\ncomments &lt;- tidyr::pivot_longer(comments, cols = c('fear', 'anger', 'anticip', 'trust', 'surprise', 'positive', 'negative', 'sadness', 'disgust', 'joy', 'anticipation'), names_to = \"emotion\", values_to = \"score\")\n\n\n# Remove the 'emotion_scores.' prefix from the emotion names\ncomments$emotion &lt;- str_remove(comments$emotion, \"emotion_scores.\")\n\n# Ensure scores are numeric\ncomments$score &lt;- as.numeric(comments$score)\n\n# Group by source and emotion, then calculate average scores\nsource_scores &lt;- comments %&gt;%\n  group_by(source, emotion) %&gt;%\n  summarise(avg_score = mean(score, na.rm = TRUE), .groups = 'drop') \n\nsource_scores\n\n# A tibble: 33 × 3\n   source    emotion      avg_score\n   &lt;chr&gt;     &lt;chr&gt;            &lt;dbl&gt;\n 1 newspaper anger           0.0522\n 2 newspaper anticip         0     \n 3 newspaper anticipation    0.160 \n 4 newspaper disgust         0.0352\n 5 newspaper fear            0.115 \n 6 newspaper joy             0.0609\n 7 newspaper negative        0.143 \n 8 newspaper positive        0.205 \n 9 newspaper sadness         0.0572\n10 newspaper surprise        0.0296\n# ℹ 23 more rows\n\n## save to a .csv file\nwrite_csv(source_scores, \"../data/source_scores.csv\")"
  },
  {
    "objectID": "scripts/voa_prep.html#code-to-topic-modeling-voa-interview-transcripts",
    "href": "scripts/voa_prep.html#code-to-topic-modeling-voa-interview-transcripts",
    "title": "voa_prep",
    "section": "",
    "text": "library(readxl)\nlibrary(quanteda)\n\nPackage version: 3.3.1\nUnicode version: 14.0\nICU version: 71.1\n\n\nParallel computing: 8 of 8 threads used.\n\n\nSee https://quanteda.io for tutorials and examples.\n\nlibrary(textTinyR)\n\nLoading required package: Matrix\n\nlibrary(tm)\n\nLoading required package: NLP\n\n\n\nAttaching package: 'NLP'\n\n\nThe following objects are masked from 'package:quanteda':\n\n    meta, meta&lt;-\n\n\n\nAttaching package: 'tm'\n\n\nThe following object is masked from 'package:quanteda':\n\n    stopwords\n\nlibrary(topicmodels)\nlibrary(RColorBrewer)\nlibrary(udpipe)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ ggplot2::annotate() masks NLP::annotate()\n✖ tidyr::expand()     masks Matrix::expand()\n✖ dplyr::filter()     masks stats::filter()\n✖ dplyr::lag()        masks stats::lag()\n✖ tidyr::pack()       masks Matrix::pack()\n✖ tidyr::unpack()     masks Matrix::unpack()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(data.table)\n\n\nAttaching package: 'data.table'\n\nThe following objects are masked from 'package:lubridate':\n\n    hour, isoweek, mday, minute, month, quarter, second, wday, week,\n    yday, year\n\nThe following objects are masked from 'package:dplyr':\n\n    between, first, last\n\nThe following object is masked from 'package:purrr':\n\n    transpose\n\nlibrary(jsonlite)\n\n\nAttaching package: 'jsonlite'\n\nThe following object is masked from 'package:purrr':\n\n    flatten\n\n## Prepare data for plotting\ninterviews &lt;- read_excel(\"../data/interviews.xlsx\")\n## label POS\nud_model &lt;- udpipe_download_model(language = \"english\")\n\nDownloading udpipe model from https://raw.githubusercontent.com/jwijffels/udpipe.models.ud.2.5/master/inst/udpipe-ud-2.5-191206/english-ewt-ud-2.5-191206.udpipe to /Users/zhiqiangji/GitRepos/ZOUXIAN/scripts/english-ewt-ud-2.5-191206.udpipe\n - This model has been trained on version 2.5 of data from https://universaldependencies.org\n - The model is distributed under the CC-BY-SA-NC license: https://creativecommons.org/licenses/by-nc-sa/4.0\n - Visit https://github.com/jwijffels/udpipe.models.ud.2.5 for model license details.\n - For a list of all models and their licenses (most models you can download with this package have either a CC-BY-SA or a CC-BY-SA-NC license) read the documentation at ?udpipe_download_model. For building your own models: visit the documentation by typing vignette('udpipe-train', package = 'udpipe')\nDownloading finished, model stored at '/Users/zhiqiangji/GitRepos/ZOUXIAN/scripts/english-ewt-ud-2.5-191206.udpipe'\n\nud_model &lt;- udpipe_load_model(ud_model$file_model)\ninterviews_annotated &lt;-  udpipe_annotate(ud_model, x = interviews$text)\ndt &lt;- as.data.table(interviews_annotated)\ndt_filtered &lt;- dt[upos %in% c(\"NOUN\", \"VERB\")]\ncorpus &lt;- Corpus(VectorSource(dt_filtered$lemma))\n\n# Preprocessing\ncorpus_clean &lt;- tm_map(corpus, content_transformer(tolower))\n\nWarning in tm_map.SimpleCorpus(corpus, content_transformer(tolower)):\ntransformation drops documents\n\ncorpus_clean &lt;- tm_map(corpus_clean, content_transformer(removePunctuation))\n\nWarning in tm_map.SimpleCorpus(corpus_clean,\ncontent_transformer(removePunctuation)): transformation drops documents\n\ncorpus_clean &lt;- tm_map(corpus_clean, content_transformer(removeNumbers))\n\nWarning in tm_map.SimpleCorpus(corpus_clean,\ncontent_transformer(removeNumbers)): transformation drops documents\n\ncorpus_clean &lt;- tm_map(corpus_clean, content_transformer(removeWords), stopwords(\"english\"))\n\nWarning in tm_map.SimpleCorpus(corpus_clean, content_transformer(removeWords),\n: transformation drops documents\n\n# Create a document-term matrix\ndtm &lt;- DocumentTermMatrix(corpus_clean)\ndtm &lt;- removeSparseTerms(dtm, 0.99) \n\n# Convert your TDM to a non-sparse format (required by LDA)\ndtm_lda &lt;- as.DocumentTermMatrix(dtm, control = list(store = \"dense\"))\n# remove all-zero rows\ndtm_lda &lt;- dtm_lda[rowSums(as.matrix(dtm_lda)) &gt; 0, ]\n\n\n# Determine number of topics\nk &lt;- 5  \n# Apply LDA\nlda_model &lt;- LDA(dtm_lda, k, method = \"Gibbs\", control = list(seed = 42))\n\ntop_terms &lt;- terms(lda_model, 20)\n\n# Store top terms as a data frame for plotting\ntop_terms_df &lt;- data.frame(t(top_terms))\ntop_terms_df$topic &lt;- seq_len(nrow(top_terms_df))\ntop_terms_df$words &lt;- apply(top_terms_df[, -ncol(top_terms_df)], 1, paste, collapse = \" \")\ntop_terms_df &lt;- top_terms_df[, c(\"topic\", \"words\")]\nhead(top_terms_df)\n\n        topic                                                 words\nTopic 1     1 say take come year leave country know people time day\nTopic 2     2 people day year country take know say come leave time\nTopic 3     3 year country leave come take know people say time day\nTopic 4     4 leave know say day year country take people come time\nTopic 5     5 time come country year take know people say leave day\n\n# Save as CSV\nwrite.csv(top_terms_df, \"../data/voa_top_terms.csv\", row.names = FALSE)\n\n\n# Prepare data for page 3\n## read in csv file\n## Read in the data from file\ncomments &lt;- read_csv(\"../data/all_comments_nlp.csv\") %&gt;%\n  select(user, source, polarity_subjectivity, emotion_scores) # select only the columns needed for the app\n\nRows: 13907 Columns: 9\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (6): user, text, source, text_clean, polarity_subjectivity, emotion_scores\ndbl (3): mentions, unique_words, length\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n## Get the column names\ncolnames(comments)\n\n[1] \"user\"                  \"source\"                \"polarity_subjectivity\"\n[4] \"emotion_scores\"       \n\n## Create a df for emotion score plotting\ncomments$emotion_scores &lt;- str_replace_all(comments$emotion_scores, \"'\", \"\\\"\")\n\n# Convert emotion_scores from JSON-like strings to lists\ncomments &lt;- comments %&gt;%\n  mutate(emotion_scores = map(emotion_scores, ~fromJSON(.x, simplifyVector = TRUE)))\n\n# Unnest the nested emotion_scores list-column to two columns, name and value\ncomments &lt;- tidyr::unnest_wider(comments, emotion_scores)\n\n# Gather all emotions into one column and their corresponding values into another column\n# Gather all emotions into one column and their corresponding values into another column\ncomments &lt;- tidyr::pivot_longer(comments, cols = c('fear', 'anger', 'anticip', 'trust', 'surprise', 'positive', 'negative', 'sadness', 'disgust', 'joy', 'anticipation'), names_to = \"emotion\", values_to = \"score\")\n\n\n# Remove the 'emotion_scores.' prefix from the emotion names\ncomments$emotion &lt;- str_remove(comments$emotion, \"emotion_scores.\")\n\n# Ensure scores are numeric\ncomments$score &lt;- as.numeric(comments$score)\n\n# Group by source and emotion, then calculate average scores\nsource_scores &lt;- comments %&gt;%\n  group_by(source, emotion) %&gt;%\n  summarise(avg_score = mean(score, na.rm = TRUE), .groups = 'drop') \n\nsource_scores\n\n# A tibble: 33 × 3\n   source    emotion      avg_score\n   &lt;chr&gt;     &lt;chr&gt;            &lt;dbl&gt;\n 1 newspaper anger           0.0522\n 2 newspaper anticip         0     \n 3 newspaper anticipation    0.160 \n 4 newspaper disgust         0.0352\n 5 newspaper fear            0.115 \n 6 newspaper joy             0.0609\n 7 newspaper negative        0.143 \n 8 newspaper positive        0.205 \n 9 newspaper sadness         0.0572\n10 newspaper surprise        0.0296\n# ℹ 23 more rows\n\n## save to a .csv file\nwrite_csv(source_scores, \"../data/source_scores.csv\")"
  },
  {
    "objectID": "p2.html",
    "href": "p2.html",
    "title": "THE END OF TREKKING",
    "section": "",
    "text": "The long route to walk"
  },
  {
    "objectID": "p2.html#the-unexpected-influx",
    "href": "p2.html#the-unexpected-influx",
    "title": "THE END OF TREKKING",
    "section": "The Unexpected Influx",
    "text": "The Unexpected Influx\nThe surge of Chinese migrants entering the United States through the Mexican border has reached unprecedented levels, leading to heightened national security concerns in the United States. Over 24,000 Chinese citizens were apprehended at the U.S-Mexico border during the 2023 fiscal year, marking a drastic increase from the 1,970 arrests that took place in the fiscal year prior, and significantly up from 2021 when only 323 Chinese nationals crossed the border during the height of pandemic travel bans and lockdowns. As the Chinese government continues to exercise strict control over its citizens, particularly in the wake of the pandemic, the influx of Chinese migrants is projected to continue, further escalating concerns of potential national security risks."
  },
  {
    "objectID": "test.html",
    "href": "test.html",
    "title": "Float Specifier",
    "section": "",
    "text": "gg\n\n\n\n\n\nHere are some texts."
  },
  {
    "objectID": "test.html#markdown-image",
    "href": "test.html#markdown-image",
    "title": "Float Specifier",
    "section": "",
    "text": "gg\n\n\n\n\n\nHere are some texts."
  },
  {
    "objectID": "test.html#text",
    "href": "test.html#text",
    "title": "Float Specifier",
    "section": "",
    "text": "Here are some texts."
  }
]